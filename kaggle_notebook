{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":119874,"databundleVersionId":14372465,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0) Problem Statement","metadata":{}},{"cell_type":"markdown","source":"Develop a PyTorch model that predicts both gender (binary classification) and age (regression) from facial images. The goal is to design, train, and evaluate models effectively. Train two models on the provided dataset. - Simple CNN from scratch - Finetuned from pretrained models.\n\n","metadata":{}},{"cell_type":"markdown","source":"# 1) Import Important Libraries for DL","metadata":{}},{"cell_type":"code","source":"!pip install torch --quiet\n!pip install torchvision --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:25:07.137475Z","iopub.execute_input":"2025-11-10T11:25:07.137772Z","iopub.status.idle":"2025-11-10T11:26:28.224010Z","shell.execute_reply.started":"2025-11-10T11:25:07.137746Z","shell.execute_reply":"2025-11-10T11:26:28.222924Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 2) Importing Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nbase_path = \"/kaggle/input/sep-25-dl-gen-ai-nppe-1/face_dataset\"\n\ntrain = pd.read_csv(f\"{base_path}/train.csv\")\ntest = pd.read_csv(f\"{base_path}/test.csv\")\n\nprint(train.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:26:28.225125Z","iopub.execute_input":"2025-11-10T11:26:28.225418Z","iopub.status.idle":"2025-11-10T11:26:28.591393Z","shell.execute_reply.started":"2025-11-10T11:26:28.225383Z","shell.execute_reply":"2025-11-10T11:26:28.590535Z"}},"outputs":[{"name":"stdout","text":"   id        full_path  gender  age\n0   0  train/00000.jpg       1   66\n1   1  train/00001.jpg       1   53\n2   2  train/00002.jpg       1   20\n3   3  train/00003.jpg       1   32\n4   4  train/00004.jpg       1   21\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(train['gender'].value_counts())\nprint(train['age'].describe())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:26:28.593031Z","iopub.execute_input":"2025-11-10T11:26:28.593510Z","iopub.status.idle":"2025-11-10T11:26:28.617750Z","shell.execute_reply.started":"2025-11-10T11:26:28.593487Z","shell.execute_reply":"2025-11-10T11:26:28.616852Z"}},"outputs":[{"name":"stdout","text":"gender\n1    26084\n0     8624\nName: count, dtype: int64\ncount    34708.000000\nmean        37.346692\nstd         16.587891\nmin          1.000000\n25%         25.000000\n50%         32.000000\n75%         48.000000\nmax        100.000000\nName: age, dtype: float64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 4) Transform","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor()\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:26:28.618681Z","iopub.execute_input":"2025-11-10T11:26:28.618984Z","iopub.status.idle":"2025-11-10T11:26:33.923591Z","shell.execute_reply.started":"2025-11-10T11:26:28.618956Z","shell.execute_reply":"2025-11-10T11:26:33.922590Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 5) All Images to Tensor","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom PIL import Image\n\nX, age, gender = [], [], []\n\nfor i, row in train.iterrows():\n    img_path = os.path.join(base_path, row['full_path'])\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img)\n    X.append(img)\n    age.append(row['age'])\n    gender.append(row['gender'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:26:33.924689Z","iopub.execute_input":"2025-11-10T11:26:33.925112Z","iopub.status.idle":"2025-11-10T11:29:37.292247Z","shell.execute_reply.started":"2025-11-10T11:26:33.925093Z","shell.execute_reply":"2025-11-10T11:29:37.291468Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\n\nX = torch.stack(X)\nage = torch.tensor(age, dtype=torch.float32)\ngender = torch.tensor(gender, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:29:37.293186Z","iopub.execute_input":"2025-11-10T11:29:37.293481Z","iopub.status.idle":"2025-11-10T11:29:38.663939Z","shell.execute_reply.started":"2025-11-10T11:29:37.293453Z","shell.execute_reply":"2025-11-10T11:29:38.663259Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# 6) Preprocessings","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\ndataset = TensorDataset(X, age, gender)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:29:38.665066Z","iopub.execute_input":"2025-11-10T11:29:38.665323Z","iopub.status.idle":"2025-11-10T11:29:38.669363Z","shell.execute_reply.started":"2025-11-10T11:29:38.665298Z","shell.execute_reply":"2025-11-10T11:29:38.668813Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n\n        # Convolutional layers\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n\n        # Fully connected (shared) part\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 16 * 16, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n\n        # Two heads for multi-task output\n        self.age_head = nn.Linear(128, 1)\n        self.gender_head = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.fc(x)\n        age = torch.sigmoid(self.age_head(x)) * 100.0  # normalize age output\n        gender = self.gender_head(x)  # raw logits for binary classification\n        return age.squeeze(1), gender.squeeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:29:38.670110Z","iopub.execute_input":"2025-11-10T11:29:38.670351Z","iopub.status.idle":"2025-11-10T11:29:38.745981Z","shell.execute_reply.started":"2025-11-10T11:29:38.670315Z","shell.execute_reply":"2025-11-10T11:29:38.745145Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 7) Instantiate","metadata":{}},{"cell_type":"code","source":"model = SimpleCNN().to(device)\n\nmse = nn.MSELoss()\nbce = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4) \n\nfrom torch.utils.data import TensorDataset, DataLoader\ndataset = TensorDataset(X, age, gender)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:29:38.748432Z","iopub.execute_input":"2025-11-10T11:29:38.748637Z","iopub.status.idle":"2025-11-10T11:29:38.932373Z","shell.execute_reply.started":"2025-11-10T11:29:38.748620Z","shell.execute_reply":"2025-11-10T11:29:38.931809Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# 8) Training Loop with Trackio","metadata":{}},{"cell_type":"code","source":"!pip install trackio --quiet\nimport trackio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:29:38.933186Z","iopub.execute_input":"2025-11-10T11:29:38.933443Z","iopub.status.idle":"2025-11-10T11:30:17.602621Z","shell.execute_reply.started":"2025-11-10T11:29:38.933421Z","shell.execute_reply":"2025-11-10T11:30:17.601995Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.0/875.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"trackio.init(project=\"my-training\", config={\n            \"epochs\": 10,\n            \"learning_rate\": 0.001,\n            \"batch_size\": 64\n        })\n\nfor epoch in range(10): \n    model.train()\n    total_loss = 0.0\n\n    for images, ages, genders in loader:\n        images, ages, genders = images.to(device), ages.to(device), genders.to(device)\n\n        optimizer.zero_grad()\n\n        age_pred, gender_pred = model(images)\n\n        loss_age = mse(age_pred, ages)\n        loss_gender = bce(gender_pred, genders)\n        loss = 0.9 * loss_age + 0.1 * loss_gender  \n\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(loader)\n    trackio.log({\n                \"epoch\": epoch,\n                \"av_loss\": avg_loss,\n                \n            })\n    print(f\"Epoch [{epoch+1}/100] — Loss: {avg_loss:.4f}\")\ntrackio.finish()\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:30:17.603400Z","iopub.execute_input":"2025-11-10T11:30:17.603625Z","iopub.status.idle":"2025-11-10T11:31:14.428442Z","shell.execute_reply.started":"2025-11-10T11:30:17.603605Z","shell.execute_reply":"2025-11-10T11:31:14.427803Z"}},"outputs":[{"name":"stdout","text":"* Running on public URL: https://37a88a5ac0c809201e.gradio.live\n* Trackio project initialized: my-training\n* Trackio metrics logged to: /root/.cache/huggingface/trackio\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://37a88a5ac0c809201e.gradio.live/?project=my-training&write_token=SdXixiZtg1jYUUT6TZ_s16AMc-tBT4SB676DDkRxnz0\" width=\"100%\" height=\"1000px\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"* Created new run: dainty-sunset-0\nEpoch [1/100] — Loss: 188.3434\nEpoch [2/100] — Loss: 161.6999\nEpoch [3/100] — Loss: 148.2428\nEpoch [4/100] — Loss: 138.9714\nEpoch [5/100] — Loss: 130.1820\nEpoch [6/100] — Loss: 122.4647\nEpoch [7/100] — Loss: 114.5915\nEpoch [8/100] — Loss: 107.0267\nEpoch [9/100] — Loss: 100.5867\nEpoch [10/100] — Loss: 94.9696\n* Run finished. Uploading logs to Trackio (please wait...)\nDone\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# 9) Show Trackio","metadata":{}},{"cell_type":"code","source":"trackio.show(project=\"my-training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:31:14.429158Z","iopub.execute_input":"2025-11-10T11:31:14.429432Z","iopub.status.idle":"2025-11-10T11:31:14.534267Z","shell.execute_reply.started":"2025-11-10T11:31:14.429411Z","shell.execute_reply":"2025-11-10T11:31:14.533700Z"}},"outputs":[{"name":"stdout","text":"* Running on public URL: https://37a88a5ac0c809201e.gradio.live\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://37a88a5ac0c809201e.gradio.live/?project=my-training&write_token=SdXixiZtg1jYUUT6TZ_s16AMc-tBT4SB676DDkRxnz0\" width=\"100%\" height=\"1000px\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"torch.save(model.state_dict(), \"age_gender_predictor.pth\")\nprint(\"Model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:31:14.534889Z","iopub.execute_input":"2025-11-10T11:31:14.535138Z","iopub.status.idle":"2025-11-10T11:31:14.554574Z","shell.execute_reply.started":"2025-11-10T11:31:14.535110Z","shell.execute_reply":"2025-11-10T11:31:14.553795Z"}},"outputs":[{"name":"stdout","text":"Model saved!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# 10) Take Test and Do Predictions","metadata":{}},{"cell_type":"code","source":"model.eval()\npred_ages, pred_genders, ids = [], [], []\n\nfor i, row in test.iterrows():\n    img_path = os.path.join(base_path, row['full_path'])\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        age_pred, gender_pred = model(img)\n        pred_ages.append(age_pred.item())                    \n        pred_genders.append(1 if torch.sigmoid(gender_pred) > 0.5 else 0)\n    ids.append(row['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:31:14.555444Z","iopub.execute_input":"2025-11-10T11:31:14.556160Z","iopub.status.idle":"2025-11-10T11:32:15.095886Z","shell.execute_reply.started":"2025-11-10T11:31:14.556139Z","shell.execute_reply":"2025-11-10T11:32:15.095237Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# 11) Fianl Convert and Submit","metadata":{}},{"cell_type":"code","source":"pred_age_int = pd.to_numeric(pred_ages).astype(int)\nsubmission = pd.DataFrame({\n    \"id\": ids,\n    \"age\": pred_age_int,\n    \"gender\": pred_genders\n})\n\nsubmission.to_csv(\"submission6.csv\", index=False)\nsubmission.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:32:15.096607Z","iopub.execute_input":"2025-11-10T11:32:15.096878Z","iopub.status.idle":"2025-11-10T11:32:15.128512Z","shell.execute_reply.started":"2025-11-10T11:32:15.096853Z","shell.execute_reply":"2025-11-10T11:32:15.127955Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   id  age  gender\n0   0   45       1\n1   1   36       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>36</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"print(submission['age'].max())\nprint(submission['age'].min())\n\nprint(submission['id'].max())\nprint(submission['id'].min())\n\nprint(submission['gender'].max())\nprint(submission['gender'].min())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:32:15.129280Z","iopub.execute_input":"2025-11-10T11:32:15.129987Z","iopub.status.idle":"2025-11-10T11:32:15.134923Z","shell.execute_reply.started":"2025-11-10T11:32:15.129962Z","shell.execute_reply":"2025-11-10T11:32:15.134274Z"}},"outputs":[{"name":"stdout","text":"83\n10\n8676\n0\n1\n1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class ResNetAgeGender(nn.Module):\n    def __init__(self):\n        super(ResNetAgeGender, self).__init__()\n\n        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        \n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n\n        self.age_head = nn.Sequential(\n            nn.Linear(num_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 1)\n        )\n        self.gender_head = nn.Sequential(\n            nn.Linear(num_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, x):\n        features = self.backbone(x)\n        age = self.age_head(features)\n        gender = self.gender_head(features)\n        return age.squeeze(1), gender.squeeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:32:15.135722Z","iopub.execute_input":"2025-11-10T11:32:15.135900Z","iopub.status.idle":"2025-11-10T11:32:15.150113Z","shell.execute_reply.started":"2025-11-10T11:32:15.135886Z","shell.execute_reply":"2025-11-10T11:32:15.149455Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = ResNetAgeGender().to(device)\n\nmse = nn.MSELoss()\nbce = nn.BCEWithLogitsLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:32:15.150825Z","iopub.execute_input":"2025-11-10T11:32:15.151055Z","iopub.status.idle":"2025-11-10T11:32:15.652851Z","shell.execute_reply.started":"2025-11-10T11:32:15.151039Z","shell.execute_reply":"2025-11-10T11:32:15.652047Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 224MB/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"for epoch in range(25):\n    model.train()\n    total_loss = 0.0\n\n    for images, ages, genders in loader:\n        images, ages, genders = images.to(device), ages.to(device), genders.to(device)\n        optimizer.zero_grad()\n\n        age_pred, gender_pred = model(images)\n        loss_age = mse(age_pred, ages)\n        loss_gender = bce(gender_pred, genders)\n        loss = 0.95 * loss_age + 0.05 * loss_gender\n\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    \n    scheduler.step()\n    avg_loss = total_loss / len(loader)\n    trackio.log({\n                \"epoch\": epoch,\n                \"av_loss\": avg_loss,\n                \n    })\n    print(f\"Epoch [{epoch+1}/10] — Loss: {avg_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"resnet_age_gender.pth\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:09:22.745954Z","iopub.execute_input":"2025-11-10T12:09:22.746242Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] — Loss: 22.6118\nEpoch [2/10] — Loss: 21.8986\nEpoch [3/10] — Loss: 21.6524\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.eval()\npred_ages, pred_genders, ids = [], [], []\n\nfor i, row in test.iterrows():\n    img_path = os.path.join(base_path, row['full_path'])\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        age_pred, gender_pred = model(img)\n        age_pred = torch.clamp(age_pred, 0, 100)\n        pred_ages.append(age_pred.item())\n        pred_genders.append(1 if torch.sigmoid(gender_pred) > 0.5 else 0)\n\n    ids.append(row['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:44:22.934995Z","iopub.execute_input":"2025-11-10T11:44:22.935290Z","iopub.status.idle":"2025-11-10T11:45:06.755853Z","shell.execute_reply.started":"2025-11-10T11:44:22.935270Z","shell.execute_reply":"2025-11-10T11:45:06.755249Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"pred_age_rst = pd.to_numeric(pred_ages).astype(int)\n\nd = ((pred_age_int*0.3+pred_age_rst*0.7)).astype(int)\nsubmission1 = pd.DataFrame({\n    \"id\": ids,\n    \"age\": pred_age_rst,\n    \"gender\": pred_genders\n})\n\nsubmission1.to_csv(\"submission1.csv\", index=False)\nsubmission1.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:45:06.756637Z","iopub.execute_input":"2025-11-10T11:45:06.756875Z","iopub.status.idle":"2025-11-10T11:45:06.780037Z","shell.execute_reply.started":"2025-11-10T11:45:06.756859Z","shell.execute_reply":"2025-11-10T11:45:06.779240Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   id  age  gender\n0   0   37       1\n1   1   34       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>37</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"class EfficientNetAgeGender(nn.Module):\n    def __init__(self):\n        super().__init__()\n        base = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n        \n        num_features = base.classifier[1].in_features\n        base.classifier = nn.Identity()\n        self.backbone = base\n\n        self.age_head = nn.Sequential(\n            nn.Linear(num_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 1)\n        )\n        self.gender_head = nn.Sequential(\n            nn.Linear(num_features, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, x):\n        x = self.backbone(x)\n        age = self.age_head(x)\n        gender = self.gender_head(x)\n        return age.squeeze(1), gender.squeeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:45:20.827703Z","iopub.execute_input":"2025-11-10T11:45:20.828210Z","iopub.status.idle":"2025-11-10T11:45:20.833772Z","shell.execute_reply.started":"2025-11-10T11:45:20.828188Z","shell.execute_reply":"2025-11-10T11:45:20.833145Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = EfficientNetAgeGender().to(device)\n\nmse = nn.MSELoss()\nbce = nn.BCEWithLogitsLoss()\n\noptimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:45:54.486526Z","iopub.execute_input":"2025-11-10T11:45:54.487115Z","iopub.status.idle":"2025-11-10T11:45:54.634737Z","shell.execute_reply.started":"2025-11-10T11:45:54.487090Z","shell.execute_reply":"2025-11-10T11:45:54.633941Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"\nfor epoch in range(20):\n    model.train()\n    total_loss = 0.0\n\n    for images, ages, genders in loader:\n        images, ages, genders = images.to(device), ages.to(device), genders.to(device)\n\n        optimizer.zero_grad()\n\n        age_pred, gender_pred = model(images)\n        loss_age = mse(age_pred, ages)\n        loss_gender = bce(gender_pred, genders)\n        loss = 0.95 * loss_age + 0.05 * loss_gender\n\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    scheduler.step()\n    avg_loss = total_loss / len(loader)\n    print(f\"Epoch [{epoch+1}/20] — Loss: {avg_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"efficientnet_age_gender.pth\")\nprint(\"✅ Model saved as efficientnet_age_gender.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T11:47:47.362628Z","iopub.execute_input":"2025-11-10T11:47:47.363392Z","iopub.status.idle":"2025-11-10T12:01:43.476372Z","shell.execute_reply.started":"2025-11-10T11:47:47.363367Z","shell.execute_reply":"2025-11-10T12:01:43.475693Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20] — Loss: 128.8566\nEpoch [2/20] — Loss: 109.2124\nEpoch [3/20] — Loss: 93.0766\nEpoch [4/20] — Loss: 81.8561\nEpoch [5/20] — Loss: 73.2651\nEpoch [6/20] — Loss: 62.0945\nEpoch [7/20] — Loss: 54.9408\nEpoch [8/20] — Loss: 50.0105\nEpoch [9/20] — Loss: 44.3533\nEpoch [10/20] — Loss: 39.5586\nEpoch [11/20] — Loss: 37.4880\nEpoch [12/20] — Loss: 33.7808\nEpoch [13/20] — Loss: 32.4853\nEpoch [14/20] — Loss: 30.5034\nEpoch [15/20] — Loss: 28.7563\nEpoch [16/20] — Loss: 27.4409\nEpoch [17/20] — Loss: 25.8797\nEpoch [18/20] — Loss: 24.8095\nEpoch [19/20] — Loss: 24.1984\nEpoch [20/20] — Loss: 23.3142\n✅ Model saved as efficientnet_age_gender.pth\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"model.eval()\npred_ages, pred_genders, ids = [], [], []\n\nfor i, row in test.iterrows():\n    img_path = os.path.join(base_path, row['full_path'])\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        age_pred, gender_pred = model(img)\n        age_pred = torch.clamp(age_pred, 0, 100)\n        pred_ages.append(age_pred.item())\n        pred_genders.append(1 if torch.sigmoid(gender_pred) > 0.5 else 0)\n\n    ids.append(row['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:03:23.916096Z","iopub.execute_input":"2025-11-10T12:03:23.916513Z","iopub.status.idle":"2025-11-10T12:05:05.093084Z","shell.execute_reply.started":"2025-11-10T12:03:23.916482Z","shell.execute_reply":"2025-11-10T12:05:05.092456Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"pred_age_eft = pd.to_numeric(pred_ages).astype(int)\n\nsubmission2 = pd.DataFrame({\n    \"id\": ids,\n    \"age\": pred_age_eft,\n    \"gender\": pred_genders\n})\n\nsubmission2.to_csv(\"submission.csv\", index=False)\nsubmission2.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:08:49.898081Z","iopub.execute_input":"2025-11-10T12:08:49.898816Z","iopub.status.idle":"2025-11-10T12:08:49.920826Z","shell.execute_reply.started":"2025-11-10T12:08:49.898794Z","shell.execute_reply":"2025-11-10T12:08:49.920018Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   id  age  gender\n0   0   39       1\n1   1   29       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>39</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>29</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30}]}